# Plan: Recherche Asynchrone avec Feedback Temps RÃ©el

## ğŸ¯ Objectif
ImplÃ©menter un systÃ¨me de recherche d'offres asynchrone avec feedback progressif pour l'utilisateur.

## ğŸ“‹ Flux SouhaitÃ©

```
1. Frontend â†’ Backend: POST /jobs/search/async
   â†“
2. Backend â†’ Frontend: RÃ©ponse immÃ©diate { task_id, status: "pending" }
   â†“
3. Frontend: Affiche spinner/barre de progression
   â†“
4. Backend: Lance Celery task pour scraping
   â†“
5. Frontend: Poll GET /jobs/search/status/{task_id} toutes les 2s
   â†“
6. Backend â†’ Frontend: Status updates
   - "pending": Recherche en file d'attente
   - "processing": Scraping en cours (X offres trouvÃ©es)
   - "completed": TerminÃ© avec succÃ¨s (retourne les offres)
   - "failed": Erreur (retourne le message d'erreur)
   â†“
7. Frontend: Affiche les rÃ©sultats ou l'erreur
```

## ğŸ”§ ImplÃ©mentation

### Backend

#### 1. Nouveau endpoint: POST /api/v1/jobs/search/async
```python
@router.post("/search/async")
async def search_jobs_async(params: SearchRequest, user: User):
    # Lance la task Celery
    task = scrape_jobs_task.delay(
        user_id=str(user.id),
        keywords=params.keywords,
        location=params.location,
        job_type=params.job_type
    )
    
    return {
        "task_id": task.id,
        "status": "pending",
        "message": "Recherche lancÃ©e"
    }
```

#### 2. Nouveau endpoint: GET /api/v1/jobs/search/status/{task_id}
```python
@router.get("/search/status/{task_id}")
async def get_search_status(task_id: str, user: User):
    task = AsyncResult(task_id)
    
    if task.state == 'PENDING':
        return {"status": "pending", "message": "En attente..."}
    elif task.state == 'STARTED':
        return {"status": "processing", "message": "Scraping en cours..."}
    elif task.state == 'SUCCESS':
        return {
            "status": "completed",
            "offers": task.result,
            "count": len(task.result)
        }
    elif task.state == 'FAILURE':
        return {"status": "failed", "error": str(task.info)}
```

#### 3. Celery Task: scrape_jobs_task
```python
@celery_app.task(bind=True)
def scrape_jobs_task(self, user_id, keywords, location, job_type):
    self.update_state(state='STARTED', meta={'message': 'Scraping dÃ©marrÃ©'})
    
    try:
        # Scraping des offres
        offers = scrape_from_platforms(keywords, location, job_type)
        
        # Mise Ã  jour progressive
        self.update_state(state='STARTED', meta={
            'message': f'{len(offers)} offres trouvÃ©es',
            'count': len(offers)
        })
        
        # Sauvegarde en base
        saved = save_offers_to_db(offers, user_id)
        
        return saved
    except Exception as e:
        self.update_state(state='FAILURE', meta={'error': str(e)})
        raise
```

### Frontend

#### 1. Fonction de recherche asynchrone
```typescript
const handleSearch = async () => {
  setSearchStatus('searching');
  
  // Lancer la recherche
  const response = await api.post('/jobs/search/async', searchParams);
  const { task_id } = response.data;
  
  // Polling du status
  const pollStatus = async () => {
    const statusResponse = await api.get(`/jobs/search/status/${task_id}`);
    const { status, offers, count, error } = statusResponse.data;
    
    if (status === 'pending' || status === 'processing') {
      setSearchStatus('searching');
      setStatusMessage(statusResponse.data.message);
      setTimeout(pollStatus, 2000); // Poll toutes les 2s
    } else if (status === 'completed') {
      setSearchStatus('success');
      setOffers(offers);
      setStatusMessage(`${count} offres trouvÃ©es`);
    } else if (status === 'failed') {
      setSearchStatus('error');
      setStatusMessage(error);
    }
  };
  
  pollStatus();
};
```

#### 2. UI avec barre de progression
```tsx
{searchStatus === 'searching' && (
  <div className="flex items-center gap-2 p-4 bg-blue-50">
    <Loader2 className="animate-spin" />
    <span>{statusMessage || 'Recherche en cours...'}</span>
  </div>
)}

{searchStatus === 'success' && (
  <div className="flex items-center gap-2 p-4 bg-green-50">
    <CheckCircle2 />
    <span>{statusMessage}</span>
  </div>
)}

{searchStatus === 'error' && (
  <div className="flex items-center gap-2 p-4 bg-red-50">
    <XCircle />
    <span>{statusMessage}</span>
  </div>
)}
```

## ğŸ“ Fichiers Ã  CrÃ©er/Modifier

### Backend
1. âœ… `backend/app/tasks/scraping_tasks.py` - Celery task pour scraping
2. âœ… `backend/app/api/job_offer.py` - Ajouter endpoints async
3. âœ… `backend/app/services/job_offer_service.py` - Logique de scraping

### Frontend
1. âœ… `frontend/src/lib/jobs.ts` - Service API pour recherche async
2. âœ… `frontend/src/app/jobs/page.tsx` - UI avec polling et feedback
3. âœ… `frontend/src/components/jobs/SearchStatus.tsx` - Composant de status

## ğŸ¨ Design du Feedback

### Ã‰tats Visuels

**Idle** (Avant recherche):
```
[ Barre de recherche ]
[  Bouton Rechercher  ]
```

**Pending** (En attente):
```
ğŸ”µ âŸ³ Recherche en file d'attente...
```

**Processing** (En cours):
```
ğŸ”µ âŸ³ Scraping en cours... (X offres trouvÃ©es)
[================>      ] 60%
```

**Completed** (SuccÃ¨s):
```
âœ… 25 offres trouvÃ©es et prÃªtes Ã  l'affichage
[Liste des offres]
```

**Failed** (Erreur):
```
âŒ Erreur: Impossible de se connecter aux plateformes
[Bouton RÃ©essayer]
```

## âš¡ Optimisations

1. **Cache Redis**: Stocker les rÃ©sultats de recherche pendant 5 min
2. **Debouncing**: Ã‰viter les recherches multiples simultanÃ©es
3. **Annulation**: Permettre d'annuler une recherche en cours
4. **Pagination**: Charger les rÃ©sultats par batch de 20

## ğŸ§ª Tests Ã  Effectuer

1. âœ… Recherche normale qui rÃ©ussit
2. âœ… Recherche qui ne trouve rien
3. âœ… Recherche qui Ã©choue (erreur rÃ©seau)
4. âœ… Recherches multiples en parallÃ¨le
5. âœ… Fermer le navigateur pendant la recherche (persistance)
6. âœ… Polling qui s'arrÃªte aprÃ¨s succÃ¨s/erreur

---

**Prochaine Ã©tape**: ImplÃ©menter le backend (Celery task + endpoints)
